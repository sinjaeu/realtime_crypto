from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.operators.empty import EmptyOperator
from datetime import datetime, timedelta, timezone
from xgboost import XGBRegressor
from sklearn.model_selection import KFold, GridSearchCV, train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score
import requests
import json
import logging
import redis
import pytz
import psycopg2
import os
import joblib
import pandas as pd
import numpy as np

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime.now(pytz.timezone('Asia/Seoul')),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'crypto_batch_processing',
    default_args=default_args,
    description='Crypto Data Batch Processing and ML Training DAG',
    schedule_interval='0 0 * * *',  # ë§¤ì¼ ìì • ì‹¤í–‰
    catchup=False,  # ê³¼ê±° ì‹¤í–‰ ê±´ë„ˆë›°ê¸°
    max_active_runs=1,  # ë™ì‹œ ì‹¤í–‰ ë°©ì§€
    tags=['crypto', 'ml', 'xgboost'],
)

def _reset_data():
    """ëª¨ë¸ í•™ìŠµ ì™„ë£Œ í›„ Redis ë°ì´í„° ì´ˆê¸°í™”"""
    pool = redis.ConnectionPool(host='redis', port=6379, db=0)
    r = redis.Redis(connection_pool=pool)
    
    try:
        r.ping()
        print("âœ… Redis ì—°ê²° ì„±ê³µ")
        
        # í˜„ì¬ ë°ì´í„° í¬ê¸° í™•ì¸
        db_size = r.dbsize()
        print(f"ğŸ“Š ì´ˆê¸°í™” ì „ Redis ë°ì´í„°: {db_size}ê°œ í‚¤")
        
        # ëª¨ë“  ë°ì´í„° ì´ˆê¸°í™”
        r.flushdb()
        print("ğŸ”„ Redis ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì´ˆê¸°í™” í›„ í™•ì¸
        db_size_after = r.dbsize()
        print(f"ğŸ“Š ì´ˆê¸°í™” í›„ Redis ë°ì´í„°: {db_size_after}ê°œ í‚¤")
        
        return True
        
    except Exception as e:
        print(f"âŒ Redis ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def _data_save():
    conn = psycopg2.connect(
        host=os.getenv('POSTGRES_HOST', 'postgres'),           # Docker ì„œë¹„ìŠ¤ëª…
        port=int(os.getenv('POSTGRES_PORT', 5432)),           # í¬íŠ¸
        database=os.getenv('POSTGRES_DB', 'airflow'),         # ë°ì´í„°ë² ì´ìŠ¤ëª…
        user=os.getenv('POSTGRES_USER', 'airflow'),           # ì‚¬ìš©ìëª…
        password=os.getenv('POSTGRES_PASSWORD', 'airflow')     # ë¹„ë°€ë²ˆí˜¸
    )
    cur = conn.cursor()

def _get_redis_data(r, symbol):
    """Redisì—ì„œ ì‹œê³„ì—´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì „ì²´ ë°ì´í„°)"""
    prices = r.lrange(symbol, 0, -1)  # ì „ì²´ ë°ì´í„° (ì²˜ìŒë¶€í„° ëê¹Œì§€)
    if prices:
        prices_str = [float(price.decode('utf-8')) for price in prices]
        return prices_str
    return []

def _data_read():
    """Redisì—ì„œ ëª¨ë“  ì½”ì¸ ë°ì´í„° ì½ê¸°"""
    pool = redis.ConnectionPool(host='redis', port=6379, db=0)
    r = redis.Redis(connection_pool=pool)
    
    try:
        r.ping()
        print("âœ… Redis ì—°ê²° ì„±ê³µ")
        
        price_keys = r.keys('price_history:*')
        price_keys = [key.decode('utf-8') for key in price_keys]
        print(f"ğŸ“Š ì´ {len(price_keys)}ê°œ ì½”ì¸ ë°ì´í„° ë°œê²¬")
        
        all_data = []
        for symbol_key in price_keys:
            data = reversed(_get_redis_data(r, symbol_key))
            symbol = symbol_key.replace('price_history:', '')
            for price in data:
                all_data.append({
                    'symbol': symbol,
                    'price': price
                })
        
        df = pd.DataFrame(all_data)
        print(f"ğŸ“ˆ Long format ë°ì´í„° í¬ê¸°: {df.shape}")
        return df
        
    except Exception as e:
        print(f"âŒ Redis ë°ì´í„° ì½ê¸° ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def _create_ml_features(df_long):
    """Long formatì„ ML í•™ìŠµìš©ìœ¼ë¡œ ë³€í™˜"""
    
    all_features = []
    
    # ì‹¬ë³¼ë³„ë¡œ ê·¸ë£¹í™”
    for symbol in df_long['symbol'].unique():
        symbol_data = df_long[df_long['symbol'] == symbol]
        prices = symbol_data['price'].values
        
        # ìœˆë„ìš° ë°©ì‹ìœ¼ë¡œ íŠ¹ì§• ìƒì„± (10ê°œ â†’ 1ê°œ ì˜ˆì¸¡)
        for i in range(len(prices) - 10):
            features = {
                'symbol': symbol,
                'price_1': float(prices[i]),
                'price_2': float(prices[i+1]), 
                'price_3': float(prices[i+2]),
                'price_4': float(prices[i+3]),
                'price_5': float(prices[i+4]),
                'price_6': float(prices[i+5]),
                'price_7': float(prices[i+6]),
                'price_8': float(prices[i+7]),
                'price_9': float(prices[i+8]),
                'price_10': float(prices[i+9]),
                'target': float(prices[i+10])
            }
            all_features.append(features)
    
    df_ml = pd.DataFrame(all_features)
    print(f"ğŸ¤– ML ë°ì´í„° í¬ê¸°: {df_ml.shape}")
    return df_ml

def _model_train():
    """ìµœì  íŒŒë¼ë¯¸í„°ë¡œ XGBoost ëª¨ë¸ í•™ìŠµ"""
    
    # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
    model_dir = 'models'
    model_file = f'{model_dir}/xgboost_best_model.pkl'
    
    try:
        # models ë””ë ‰í† ë¦¬ ìƒì„±
        if not os.path.exists(model_dir):
            os.makedirs(model_dir)
            print(f"ğŸ“ {model_dir} ë””ë ‰í† ë¦¬ ìƒì„±")
        
        # 1. ë°ì´í„° ë¡œë“œ
        print("ğŸ”„ Redisì—ì„œ ë°ì´í„° ë¡œë”© ì¤‘...")
        df_long = _data_read()
        
        if df_long.empty:
            print("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return False
            
        # 2. ML íŠ¹ì§• ìƒì„±
        print("ğŸ”§ ML íŠ¹ì§• ìƒì„± ì¤‘...")
        df_ml = _create_ml_features(df_long)
        
        if df_ml.empty:
            print("âŒ ML íŠ¹ì§• ìƒì„± ì‹¤íŒ¨. í•™ìŠµì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return False
        
        # 3. ë°ì´í„° ì „ì²˜ë¦¬
        print("ğŸ¯ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        le = LabelEncoder()
        df_ml['symbol_encoded'] = le.fit_transform(df_ml['symbol'])
        
        # íŠ¹ì§• ì„ íƒ
        feature_cols = ['symbol_encoded', 'price_1', 'price_2', 'price_3', 
                       'price_4', 'price_5', 'price_6', 'price_7', 
                       'price_8', 'price_9', 'price_10']
        
        X = df_ml[feature_cols]
        y = df_ml['target']
        
        # 4. Train/Test ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, shuffle=False  # ì‹œê³„ì—´ ë°ì´í„°ì´ë¯€ë¡œ shuffle=False
        )
        
        # 5. ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ìƒì„±
        print("ğŸ¤– XGBoost ëª¨ë¸ í•™ìŠµ ì¤‘...")
        optimal_params = {
            'booster': 'gbtree', 
            'eta': 0.1, 
            'gamma': 0, 
            'max_depth': 10, 
            'min_child_weight': 0.5, 
            'objective': 'reg:linear'
        }
        
        xgb_model = XGBRegressor(**optimal_params)
        
        # 6. ëª¨ë¸ í•™ìŠµ
        xgb_model.fit(X_train, y_train)
        
        # 7. ëª¨ë¸ í‰ê°€
        train_score = xgb_model.score(X_train, y_train)
        test_score = xgb_model.score(X_test, y_test)
        
        y_pred = xgb_model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # 8. ëª¨ë¸ ì €ì¥
        joblib.dump(xgb_model, model_file)
        joblib.dump(le, f'{model_dir}/label_encoder.pkl')  # LabelEncoderë„ ì €ì¥
        
        # 9. ê²°ê³¼ ì¶œë ¥
        print("ğŸ‰ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
        print(f"ğŸ“Š í›ˆë ¨ ë°ì´í„° í¬ê¸°: {X_train.shape}")
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {X_test.shape}")
        print(f"ğŸ¯ Train RÂ²: {train_score:.6f}")
        print(f"ğŸ¯ Test RÂ²: {test_score:.6f}")
        print(f"ğŸ“‰ MSE: {mse:.2f}")
        print(f"ğŸ“ˆ RÂ² Score: {r2:.6f}")
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {model_file}")
        print(f"ğŸ·ï¸ LabelEncoder ì €ì¥: {model_dir}/label_encoder.pkl")
        
        return True
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


reset_data = PythonOperator(
    task_id = 'reset_data',
    python_callable = _reset_data,
    dag = dag
)

model_train = PythonOperator(
    task_id = 'model_train',
    python_callable = _model_train,
    dag = dag
)

model_train >> reset_data